{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Your Chatbot with Supervised Fine-Tuning\n",
    "\n",
    "SFT, or Supervised Fine-Tuning, is a method used in the development of Large Language Models (LLMs) to improve model performance by training it on specific tasks or datasets with labeled examples. It’s an essential process for aligning a base model—often a general-purpose LLM that’s been pre-trained on vast amounts of unsupervised text data—to perform well on more specialized tasks or to follow specific user instructions effectively.\n",
    "\n",
    "In this notebook, we will demonstrate how to fine-tune a pre-trained Qwen model on a conversational dataset to create a chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "To run this notebook, you need to install TRL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install trl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model a bit before fine-tuning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play with her toys and watch the stars. One day, she found a special toy that could make her see in different colors. She named it the \"Color Wheel.\" \n",
      "\n",
      "One day, Lily decided to play with her toy and saw a rainbow of colors. She noticed that the colors were not in order, but she wanted to know how to make them look like they were in order. \n",
      "\n",
      "Lily thought about it and decided to use her \"Color Wheel\" to help her. She started by looking at the colors in the rainbow and trying to figure out how to make them look like they were\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = \"Once upon a time, there was a\"\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "output = generator(prompt, max_new_tokens=128)[0]\n",
    "print(output[\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fascinating story."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
